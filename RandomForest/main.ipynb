{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, os, numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mediapipe as mp\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_directory = 'FullDataset' \n",
    "output_directory = 'TrainingImages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_square(image, final_size):\n",
    "    # Obter as dimensões da imagem\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Calculate the size of the square\n",
    "    side_square = max(height, width)\n",
    "\n",
    "    # Create a new square image with black border\n",
    "    square_image = np.zeros((side_square, side_square, 3), dtype=np.uint8)\n",
    "\n",
    "    # Insert the image in the middle of the new square image\n",
    "    y_offset = (side_square - height) // 2\n",
    "    x_offset = (side_square - width) // 2\n",
    "    \n",
    "    # Convert grayscale image to 3 channels\n",
    "    color_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "    square_image[y_offset:y_offset + height, x_offset:x_offset + width] = color_image\n",
    "\n",
    "    # Resize to desired final size\n",
    "    square_image = cv2.resize(square_image, (final_size, final_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    return square_image\n",
    "\n",
    "for letter_folder in os.listdir(target_directory):\n",
    "    letter_path = os.path.join(target_directory, letter_folder)\n",
    "    \n",
    "    if os.path.isdir(letter_path):\n",
    "        for image_file in os.listdir(letter_path):\n",
    "            image_path = os.path.join(letter_path, image_file)\n",
    "            \n",
    "            try:\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                    final_image = transform_to_square(gray_image, 512)\n",
    "                    \n",
    "                    border_width = 10 \n",
    "                    image_with_border = cv2.copyMakeBorder(\n",
    "                        final_image,\n",
    "                        border_width,\n",
    "                        border_width,\n",
    "                        border_width,\n",
    "                        border_width,\n",
    "                        cv2.BORDER_CONSTANT,\n",
    "                        value=[0, 0, 0]  \n",
    "                    )\n",
    "\n",
    "                    image_with_border = cv2.resize(image_with_border, (512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "                                        \n",
    "                    output_path = os.path.join(output_directory, letter_folder)\n",
    "                    os.makedirs(output_path, exist_ok=True)\n",
    "                    \n",
    "                    gray_image_path = os.path.join(output_path, image_file)\n",
    "                    cv2.imwrite(gray_image_path, image_with_border)\n",
    "       \n",
    "            except Exception as e:\n",
    "                print(f\"Error to open image {image_path} : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] O sistema não pode encontrar o caminho especificado: 'TrainingImages'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Loop through each subfolder (each letter of the alphabet)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_directory\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     28\u001b[0m     label_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_directory, label)\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Check if it's a directory (skip files in the main folder, if any)\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] O sistema não pode encontrar o caminho especificado: 'TrainingImages'"
     ]
    }
   ],
   "source": [
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1)\n",
    "\n",
    "# Function to extract hand landmarks\n",
    "def extract_hand_landmarks(image_path):\n",
    "    # Load the grayscale image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Convert grayscale image to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # Process the image to find hand landmarks\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        landmarks = results.multi_hand_landmarks[0]\n",
    "        return [(lm.x, lm.y) for lm in landmarks.landmark]\n",
    "    return None\n",
    "\n",
    "# Directory containing ASL images organized by letter\n",
    "image_directory = 'TrainingImages'\n",
    "# List to hold data\n",
    "data = []\n",
    "\n",
    "# Loop through each subfolder (each letter of the alphabet)\n",
    "for label in os.listdir(image_directory):\n",
    "    label_path = os.path.join(image_directory, label)\n",
    "    \n",
    "    # Check if it's a directory (skip files in the main folder, if any)\n",
    "    if os.path.isdir(label_path):\n",
    "        # Loop through images in each subfolder\n",
    "        for filename in os.listdir(label_path):\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "                image_path = os.path.join(label_path, filename)\n",
    "                landmarks = extract_hand_landmarks(image_path)\n",
    "                \n",
    "                if landmarks:\n",
    "                    # Append the label and landmarks to the data list\n",
    "                    data.append([label] + [coord for landmark in landmarks for coord in landmark])\n",
    "    \n",
    "\n",
    "# Create a DataFrame\n",
    "columns = ['Label'] + [f'Landmark_{i}_{axis}' for i in range(21) for axis in ['x', 'y']]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('asl_landmarks.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "# Load data from generated CSV\n",
    "df = pd.read_csv('asl_landmarks.csv')\n",
    "df['Label'] = le.fit_transform(df['Label'])\n",
    "\n",
    "# Separate features (Landmarks) and target (Label)\n",
    "X = df.drop('Label', axis=1)  # All landmark points are features\n",
    "y = df['Label']               # The Label column is the target\n",
    "\n",
    "# Split into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Instantiate and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "prev_test = y_pred  # Model predictions\n",
    "class_test = y_test  # Actual test set classes\n",
    "\n",
    "print(f\"Acurácia: {accuracy}\")\n",
    "print(f\"Relatório de Classificação:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img():\n",
    "    path = Path(\"../Image\")\n",
    "\n",
    "    for file in path.glob(\"*\"):\n",
    "        if file.is_file():\n",
    "            return str(file)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted letter is: G\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\disrct\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
      "c:\\Users\\disrct\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get the model and load it\n",
    "model_file = \"model-rf.pkl\"\n",
    "load_model = joblib.load(model_file)\n",
    "\n",
    "label_file = \"label-encoder.pkl\"\n",
    "encoder = joblib.load(label_file)\n",
    "\n",
    "# Inicialize o MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Function to extract landmarks from a new image and make prediction\n",
    "def predict_letter(image_path, model):\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    if image is None:\n",
    "        return None\n",
    "\n",
    "    # Process image to get the landmarks\n",
    "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Known if the hand is detected\n",
    "    if results.multi_hand_landmarks:\n",
    "        \n",
    "        # Extract the landmarks\n",
    "        landmarks = results.multi_hand_landmarks[0]\n",
    "\n",
    "        # Format the coordinates\n",
    "        landmark_data = [coord for lm in landmarks.landmark for coord in (lm.x, lm.y)]\n",
    "        \n",
    "        # Make prediction with the model\n",
    "        prediction = model.predict([landmark_data])\n",
    "        \n",
    "        predicted_letter = encoder.inverse_transform(prediction)\n",
    "        \n",
    "        return predicted_letter[0]  # Retorna a letra prevista\n",
    "    else:\n",
    "        return \"Error: There's no hand on the image\"\n",
    "\n",
    "image_path = get_img()\n",
    "predicted_letter = predict_letter(image_path, load_model)\n",
    "print(f\"The predicted letter is: {predicted_letter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentual de Acertos 96.52%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Saving model using Joblib\n",
    "file_joblib = \"model-rf.pkl\"\n",
    "joblib.dump(rf_model, file_joblib, compress=True)\n",
    "\n",
    "# Loading model using Joblib\n",
    "loading_model_joblib = joblib.load(file_joblib)\n",
    "result = loading_model_joblib.score(X_test, y_test)\n",
    "print(f\"Percentual de Acertos {(result*100):.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_label_enconder = \"label-encoder.pkl\"\n",
    "joblib.dump(le, file_label_enconder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
